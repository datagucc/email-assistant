# generate_prototypes.py
from openai import OpenAI
import os
import json
import openai
from email import policy
from email.parser import BytesParser
# c'est utilis√© pour cr√©er une barre de progression pour les boucles et autres it√©rations.
from tqdm import tqdm
import sys
project_path = '/Users/focus_profond/GIT_repo/email_assistant'
if project_path not in sys.path:
    sys.path.append(project_path)

from Modules.mail_reader import parse_eml_file

# Configure ton API key
from Config.config import OPENAI_API_KEY
client = OpenAI(api_key=OPENAI_API_KEY)



# R√©pertoire contenant les sous-dossiers par cat√©gorie
#BASE_DIR = "categorized_emails"
BASE_DIR ="/Users/focus_profond/GIT_repo/email_assistant/Data/input/eml_categories"
OUTPUT_DIR = "/Users/focus_profond/GIT_repo/email_assistant/Data/prototypes"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Liste des nouvelles cat√©gories
CATEGORIES = [
    "professional", "personal", "administrative", "newsletters",
    "notifications", "job_search_answers", "job_search_applications",
    "job_search_platforms", "spam"
]

def extract_body_from_eml(filepath):
    """Extrait le body texte d‚Äôun .eml"""
    with open(filepath, 'rb') as f:
        msg = BytesParser(policy=policy.default).parse(f)
    subject = msg.get("Subject", "")
    body = ""
    if msg.is_multipart():
        for part in msg.walk():
            if part.get_content_type() == "text/plain":
                try:
                    body += part.get_content().strip() + "\n"
                except:
                    continue
    else:
        try:
            body = msg.get_content()
        except:
            pass
    return (subject + "\n" + body).strip()



def summarize_with_gpt(text, category,lang='fr'):
    """Appelle l‚ÄôAPI GPT pour cr√©er un prototype synth√©tique"""
    if lang=='fr':
        lang='francais'
    elif lang =='es':
        lang='espagnol'
    else:
        lang='anglais'
    prompt = f"""
Lis cet email ci-dessous et transforme-le en un prototype clair, fluide et typique d‚Äôun email de type ¬´{category}¬ª.

R√®gles :
- R√©sume le contenu sans inventer ni paraphraser inutilement.
- Ne change pas de ton.
- Le texte final (= le prototype) doit √™tre en {lang}
- Le texte final (=le prototype) doit faire entre 3 et 8 lignes, √™tre fluide et repr√©sentatif.
- Ne pr√©cise pas que c‚Äôest un r√©sum√©.
- Ne mentionne pas que tu es un assistant IA.

Email original :
{text}

Prototype :
"""
    try:
        #return response.choices[0].message.content.strip()
        response = client.chat.completions.create(
            model="gpt-3.5-turbo"
            ,messages=[
                {"role":"system", "content":"Tu es un assistant sp√©cialis√© en cat√©gorisation d'emails. Ton but est de produire un exemple repr√©sentatif (prototype) d'un mail pour une cat√©gorie donn√©e."}
                ,{"role": "user", "content": prompt.strip()}]
            #au plus il va √™tre faible, au plus l'IA sera feineante et pertinente.
            ,max_tokens=200
            ,temperature=0.3)
        
        # R√©cup√©ration de la r√©ponse
        prototype = response.choices[0].message.content.strip().lower()
        return prototype

    except Exception as e:
        print(f"‚ö†Ô∏è Erreur GPT : {e}")
        return None


def process_category(category):
    """G√©n√®re les prototypes d‚Äôune cat√©gorie"""
    folder_path = os.path.join(BASE_DIR, category)
    prototypes = []
    files = [f for f in os.listdir(folder_path) if f.endswith(".eml")]

    print(f"\nüìÇ Traitement cat√©gorie: {category} ({len(files)} mails)")
    for filename in tqdm(files):
        path = os.path.join(folder_path, filename)
        #je vais plutot appeler eml_reader qui permet de limiter et nettoyer le body.
        dict_email= parse_eml_file(path)
        body = dict_email['body']
        subject = dict_email['subject']
        lang = dict_email['lang']
        raw_text=(subject + "\n" + body).strip() 
        #raw_text = extract_body_from_eml(path)

        if len(raw_text.split()) < 30:  # √âvite les mails trop courts
            continue

        prototype = summarize_with_gpt(raw_text, category,lang)
        if prototype:
            prototypes.append(prototype)

    # Sauvegarde
    outpath = os.path.join(OUTPUT_DIR, f"{category}_prototypes.json")
    with open(outpath, "w", encoding="utf-8") as f:
        json.dump(prototypes, f, ensure_ascii=False, indent=2)
    print(f"‚úÖ Sauvegard√© : {outpath} ({len(prototypes)} prototypes)")


def main():
    for category in CATEGORIES:
        #if category not in ['spam','administrative','personal','professional']:
        if category =='newsletters':
            process_category(category)


if __name__ == "__main__":
    main()


#usage avant classification : 74 759
#usage apr√®s classification : 220 934 (mais j'ai du le recommencer plusieurs fois, j'i pas √©t√© super pr√©cis)
# dans tout les cas, √ßa a cout√© litterallement moins de 10 centimes.

#usage apr√®s l'avoir ex√©cut√© sur 11 √©l√©ments : 228 139